{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kobert_mxnet_256_16.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4yQI43R5rR4j","colab_type":"code","outputId":"604ef55f-90e0-4f62-fd84-dd7cefd9b2ad","executionInfo":{"status":"ok","timestamp":1577080803729,"user_tz":-540,"elapsed":8099,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["!pip install mxnet-cu101\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1.post0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (0.8.4)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.17.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.21.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.8)\n","Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.8.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.17.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U_IgtCIGrp0z","colab_type":"code","outputId":"a8cc3c91-6f87-4be4-8834-dc44253f0361","executionInfo":{"status":"ok","timestamp":1577080807557,"user_tz":-540,"elapsed":11916,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-sr5ew1of\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-sr5ew1of\n","Requirement already satisfied (use --upgrade to upgrade): kobert==0.1.1 from git+https://****@github.com/SKTBrain/KoBERT.git@master in /usr/local/lib/python3.6/dist-packages\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.1-cp36-none-any.whl size=12773 sha256=f45e0298ec377f15b43e29c26c6ef0fd01c9f9dfb98685debfb05f49682ae3aa\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ba1sc0ws/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n","Successfully built kobert\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UA7Z5-cyrrgz","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from mxnet.gluon import nn, rnn\n","from mxnet import gluon, autograd\n","import gluonnlp as nlp\n","from mxnet import nd \n","import mxnet as mx\n","import time\n","import itertools\n","import random\n","\n","from kobert.mxnet_kobert import get_mxnet_kobert_model\n","from kobert.utils import get_tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sJJc1lrvrvXL","colab_type":"text"},"source":["### Loading KoBERT"]},{"cell_type":"code","metadata":{"id":"n74huSc5rtf7","colab_type":"code","colab":{}},"source":["ctx = mx.gpu()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZZSZxsMr0fk","colab_type":"code","outputId":"5b372fc2-a8d8-41e6-9aa5-c7dface619bf","executionInfo":{"status":"ok","timestamp":1577080812057,"user_tz":-540,"elapsed":16393,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["using cached model\n","using cached model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VCxeeZ4mr2RD","colab_type":"code","outputId":"f9371bb8-6c8f-4fe1-b364-8cff3d175b77","executionInfo":{"status":"ok","timestamp":1577080812058,"user_tz":-540,"elapsed":16387,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["using cached model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xbXzvOnQsBGL","colab_type":"text"},"source":["### Loading Data"]},{"cell_type":"code","metadata":{"id":"FfUQ1SVJr5Rz","colab_type":"code","outputId":"cbef4ac7-34e0-406b-b615-6e7f2584a4b4","executionInfo":{"status":"ok","timestamp":1577080814247,"user_tz":-540,"elapsed":18566,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_gnrUaeMsPIE","colab_type":"code","outputId":"6b3a4a50-de63-4831-b1df-3f36e4a13a38","executionInfo":{"status":"ok","timestamp":1577080814248,"user_tz":-540,"elapsed":18559,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd /gdrive/My \\Drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uTkXdDEsSVT","colab_type":"code","colab":{}},"source":["dataset_train = nlp.data.TSVDataset(\"train_1.txt\", num_discard_samples=1)  # header 제거\n","dataset_test = nlp.data.TSVDataset(\"test_1.txt\", num_discard_samples=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"be0GQjBYspd7","colab_type":"code","colab":{}},"source":["class BERTDataset(mx.gluon.data.Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","        sent_dataset = gluon.data.SimpleDataset([[\n","            i[sent_idx],\n","        ] for i in dataset])\n","        self.sentences = sent_dataset.transform(transform)\n","        self.labels = gluon.data.SimpleDataset(\n","            [np.array(np.int32(i[label_idx])) for i in dataset])\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1E3UfYPssqb","colab_type":"code","colab":{}},"source":["max_len = 256\n","\n","# OOM issue 때문에 조절이 필요\n","# 128에 batch size 32로 하거나\n","# 256에 batch size 16으로 할 것\n","# 그 이상으로 긴 sequence들은 그냥 잘리게 됨"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLT1yglGsywr","colab_type":"code","colab":{}},"source":["data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJJCQA2b3T6W","colab_type":"code","outputId":"adc79c2e-2d7a-46a3-ab28-a5988ffe8db2","executionInfo":{"status":"ok","timestamp":1577080814755,"user_tz":-540,"elapsed":19023,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(data_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22511"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"AtQHiw2Us1V0","colab_type":"code","colab":{}},"source":["class BERTClassifier(nn.Block):\n","    def __init__(self,\n","                 bert,\n","                 num_classes=2,\n","                 dropout=None,\n","                 prefix=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n","        self.bert = bert\n","        with self.name_scope():\n","            self.classifier = nn.HybridSequential(prefix=prefix)\n","            if dropout:\n","                self.classifier.add(nn.Dropout(rate=dropout))\n","            self.classifier.add(nn.Dense(units=num_classes))\n","\n","    def forward(self, inputs, token_types, valid_length=None):\n","        _, pooler = self.bert(inputs, token_types, valid_length)\n","        return self.classifier(pooler)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kg9MWnmJs-Zr","colab_type":"code","colab":{}},"source":["model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n","# 분류 레이어만 초기화 한다. \n","model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n","model.hybridize()\n","\n","# softmax cross entropy loss for classification\n","loss_function = gluon.loss.SoftmaxCELoss()\n","\n","metric = mx.metric.Accuracy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BqGKujrwtBaz","colab_type":"code","colab":{}},"source":["batch_size = 16\n","lr = 5e-5\n","\n","train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6W2h-mLtGJt","colab_type":"code","colab":{}},"source":["trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n","                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n","\n","log_interval = 4\n","num_epochs = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hQC2kGptKE1","colab_type":"code","colab":{}},"source":["# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n","for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n","    v.wd_mult = 0.0\n","params = [\n","    p for p in model.collect_params().values() if p.grad_req != 'null'\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WGZqsIhDtNCN","colab_type":"code","colab":{}},"source":["def evaluate_accuracy(model, data_iter, ctx=ctx):\n","    acc = mx.metric.Accuracy()\n","    i = 0\n","    for i, (t,v,s, label) in enumerate(data_iter):\n","        token_ids = t.as_in_context(ctx)\n","        valid_length = v.as_in_context(ctx)\n","        segment_ids = s.as_in_context(ctx)\n","        label = label.as_in_context(ctx)\n","        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n","        acc.update(preds=output, labels=label)\n","        if i > 1000:\n","            break\n","        i += 1\n","    return(acc.get()[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHXxsGY-tRO1","colab_type":"code","colab":{}},"source":["#learning rate warmup을 위한 준비 \n","accumulate = 4\n","step_size = batch_size * accumulate if accumulate else batch_size\n","num_train_examples = len(data_train)\n","num_train_steps = int(num_train_examples / step_size * num_epochs)\n","warmup_ratio = 0.1\n","num_warmup_steps = int(num_train_steps * warmup_ratio)\n","step_num = 0\n","all_model_params = model.collect_params()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRjB2PGJtUuc","colab_type":"code","colab":{}},"source":["# Set grad_req if gradient accumulation is required\n","if accumulate and accumulate > 1:\n","    for p in params:\n","        p.grad_req = 'add'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"npJxRxiptYjE","colab_type":"code","outputId":"f9bfa3ae-f8f2-4b25-9a4c-97cb2e7a92c6","executionInfo":{"status":"ok","timestamp":1577071949948,"user_tz":-540,"elapsed":1739418,"user":{"displayName":"­이명진(대학원/일반대학원 심리학과)","photoUrl":"","userId":"05277611768550171044"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch_id in range(num_epochs):\n","    metric.reset()\n","    step_loss = 0\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n","        if step_num < num_warmup_steps:\n","            new_lr = lr * step_num / num_warmup_steps\n","        else:\n","            non_warmup_steps = step_num - num_warmup_steps\n","            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n","            new_lr = lr - offset * lr\n","        trainer.set_learning_rate(new_lr)\n","        with mx.autograd.record():\n","            # load data to GPU\n","            token_ids = token_ids.as_in_context(ctx)\n","            valid_length = valid_length.as_in_context(ctx)\n","            segment_ids = segment_ids.as_in_context(ctx)\n","            label = label.as_in_context(ctx)\n","\n","            # forward computation\n","            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n","            ls = loss_function(out, label).mean()\n","\n","        # backward computation\n","        ls.backward()\n","        if not accumulate or (batch_id + 1) % accumulate == 0:\n","          trainer.allreduce_grads()\n","          nlp.utils.clip_grad_global_norm(params, 1)\n","          trainer.update(accumulate if accumulate else 1)\n","          step_num += 1\n","          if accumulate and accumulate > 1:\n","              # set grad to zero for gradient accumulation\n","              all_model_params.zero_grad()\n","\n","        step_loss += ls.asscalar()\n","        metric.update([label], [out])\n","        if (batch_id + 1) % (50) == 0:\n","            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n","                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n","                                 step_loss / log_interval,\n","                                 trainer.learning_rate, metric.get()[1]))\n","            step_loss = 0\n","    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n","    print('Test Acc : {}'.format(test_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Epoch 1 Batch 50/1407] loss=8.9114, lr=0.0000034286, acc=0.501\n","[Epoch 1 Batch 100/1407] loss=7.9868, lr=0.0000068571, acc=0.583\n","[Epoch 1 Batch 150/1407] loss=8.1951, lr=0.0000105714, acc=0.605\n","[Epoch 1 Batch 200/1407] loss=7.9683, lr=0.0000140000, acc=0.622\n","[Epoch 1 Batch 250/1407] loss=8.0039, lr=0.0000177143, acc=0.631\n","[Epoch 1 Batch 300/1407] loss=7.8539, lr=0.0000211429, acc=0.641\n","[Epoch 1 Batch 350/1407] loss=7.8489, lr=0.0000248571, acc=0.648\n","[Epoch 1 Batch 400/1407] loss=8.0319, lr=0.0000282857, acc=0.651\n","[Epoch 1 Batch 450/1407] loss=7.7213, lr=0.0000320000, acc=0.657\n","[Epoch 1 Batch 500/1407] loss=7.9853, lr=0.0000354286, acc=0.658\n","[Epoch 1 Batch 550/1407] loss=8.1245, lr=0.0000391429, acc=0.657\n","[Epoch 1 Batch 600/1407] loss=8.0175, lr=0.0000425714, acc=0.658\n","[Epoch 1 Batch 650/1407] loss=8.0751, lr=0.0000462857, acc=0.658\n","[Epoch 1 Batch 700/1407] loss=7.9791, lr=0.0000497143, acc=0.660\n","[Epoch 1 Batch 750/1407] loss=8.0632, lr=0.0000496210, acc=0.661\n","[Epoch 1 Batch 800/1407] loss=7.9503, lr=0.0000492419, acc=0.661\n","[Epoch 1 Batch 850/1407] loss=7.9002, lr=0.0000488313, acc=0.663\n","[Epoch 1 Batch 900/1407] loss=8.1699, lr=0.0000484523, acc=0.662\n","[Epoch 1 Batch 950/1407] loss=8.1052, lr=0.0000480417, acc=0.662\n","[Epoch 1 Batch 1000/1407] loss=8.0442, lr=0.0000476627, acc=0.663\n","[Epoch 1 Batch 1050/1407] loss=7.7572, lr=0.0000472521, acc=0.665\n","[Epoch 1 Batch 1100/1407] loss=8.1495, lr=0.0000468730, acc=0.665\n","[Epoch 1 Batch 1150/1407] loss=7.9631, lr=0.0000464624, acc=0.665\n","[Epoch 1 Batch 1200/1407] loss=7.9211, lr=0.0000460834, acc=0.665\n","[Epoch 1 Batch 1250/1407] loss=7.9262, lr=0.0000456728, acc=0.666\n","[Epoch 1 Batch 1300/1407] loss=7.9345, lr=0.0000452937, acc=0.667\n","[Epoch 1 Batch 1350/1407] loss=7.8958, lr=0.0000448831, acc=0.667\n","[Epoch 1 Batch 1400/1407] loss=7.9589, lr=0.0000445041, acc=0.668\n","Test Acc : 0.6725584717014819\n","[Epoch 2 Batch 50/1407] loss=8.2134, lr=0.0000440619, acc=0.639\n","[Epoch 2 Batch 100/1407] loss=7.9775, lr=0.0000436829, acc=0.652\n","[Epoch 2 Batch 150/1407] loss=8.1514, lr=0.0000432723, acc=0.652\n","[Epoch 2 Batch 200/1407] loss=7.9341, lr=0.0000428932, acc=0.657\n","[Epoch 2 Batch 250/1407] loss=7.9443, lr=0.0000424826, acc=0.659\n","[Epoch 2 Batch 300/1407] loss=7.8128, lr=0.0000421036, acc=0.664\n","[Epoch 2 Batch 350/1407] loss=7.8151, lr=0.0000416930, acc=0.668\n","[Epoch 2 Batch 400/1407] loss=7.9413, lr=0.0000413140, acc=0.669\n","[Epoch 2 Batch 450/1407] loss=7.6862, lr=0.0000409033, acc=0.672\n","[Epoch 2 Batch 500/1407] loss=8.1340, lr=0.0000405243, acc=0.672\n","[Epoch 2 Batch 550/1407] loss=8.0822, lr=0.0000401137, acc=0.670\n","[Epoch 2 Batch 600/1407] loss=8.0507, lr=0.0000397347, acc=0.670\n","[Epoch 2 Batch 650/1407] loss=8.0703, lr=0.0000393241, acc=0.669\n","[Epoch 2 Batch 700/1407] loss=7.9108, lr=0.0000389450, acc=0.670\n","[Epoch 2 Batch 750/1407] loss=7.9234, lr=0.0000385344, acc=0.670\n","[Epoch 2 Batch 800/1407] loss=8.0420, lr=0.0000381554, acc=0.670\n","[Epoch 2 Batch 850/1407] loss=7.8142, lr=0.0000377448, acc=0.671\n","[Epoch 2 Batch 900/1407] loss=8.1109, lr=0.0000373658, acc=0.670\n","[Epoch 2 Batch 950/1407] loss=8.0820, lr=0.0000369551, acc=0.669\n","[Epoch 2 Batch 1000/1407] loss=7.8616, lr=0.0000365761, acc=0.670\n","[Epoch 2 Batch 1050/1407] loss=7.6535, lr=0.0000361655, acc=0.671\n","[Epoch 2 Batch 1100/1407] loss=8.0560, lr=0.0000357865, acc=0.671\n","[Epoch 2 Batch 1150/1407] loss=7.9472, lr=0.0000353759, acc=0.671\n","[Epoch 2 Batch 1200/1407] loss=7.8886, lr=0.0000349968, acc=0.671\n","[Epoch 2 Batch 1250/1407] loss=7.7887, lr=0.0000345862, acc=0.672\n","[Epoch 2 Batch 1300/1407] loss=7.9238, lr=0.0000342072, acc=0.672\n","[Epoch 2 Batch 1350/1407] loss=7.8793, lr=0.0000337966, acc=0.672\n","[Epoch 2 Batch 1400/1407] loss=7.9150, lr=0.0000334176, acc=0.673\n","Test Acc : 0.6725584717014819\n","[Epoch 3 Batch 50/1407] loss=8.2203, lr=0.0000329754, acc=0.639\n","[Epoch 3 Batch 100/1407] loss=8.0079, lr=0.0000325963, acc=0.652\n","[Epoch 3 Batch 150/1407] loss=8.0967, lr=0.0000321857, acc=0.652\n","[Epoch 3 Batch 200/1407] loss=7.9642, lr=0.0000318067, acc=0.657\n","[Epoch 3 Batch 250/1407] loss=7.9806, lr=0.0000313961, acc=0.659\n","[Epoch 3 Batch 300/1407] loss=7.7291, lr=0.0000310171, acc=0.664\n","[Epoch 3 Batch 350/1407] loss=7.7657, lr=0.0000306064, acc=0.668\n","[Epoch 3 Batch 400/1407] loss=7.9183, lr=0.0000302274, acc=0.669\n","[Epoch 3 Batch 450/1407] loss=7.6677, lr=0.0000298168, acc=0.672\n","[Epoch 3 Batch 500/1407] loss=7.9942, lr=0.0000294378, acc=0.672\n","[Epoch 3 Batch 550/1407] loss=8.0918, lr=0.0000290272, acc=0.670\n","[Epoch 3 Batch 600/1407] loss=8.0198, lr=0.0000286481, acc=0.670\n","[Epoch 3 Batch 650/1407] loss=8.0663, lr=0.0000282375, acc=0.669\n","[Epoch 3 Batch 700/1407] loss=7.9465, lr=0.0000278585, acc=0.670\n","[Epoch 3 Batch 750/1407] loss=7.9020, lr=0.0000274479, acc=0.670\n","[Epoch 3 Batch 800/1407] loss=7.9747, lr=0.0000270689, acc=0.670\n","[Epoch 3 Batch 850/1407] loss=7.8158, lr=0.0000266582, acc=0.671\n","[Epoch 3 Batch 900/1407] loss=8.1077, lr=0.0000262792, acc=0.670\n","[Epoch 3 Batch 950/1407] loss=8.0449, lr=0.0000258686, acc=0.669\n","[Epoch 3 Batch 1000/1407] loss=7.8519, lr=0.0000254896, acc=0.670\n","[Epoch 3 Batch 1050/1407] loss=7.6787, lr=0.0000250790, acc=0.671\n","[Epoch 3 Batch 1100/1407] loss=8.0609, lr=0.0000246999, acc=0.671\n"],"name":"stdout"}]}]}